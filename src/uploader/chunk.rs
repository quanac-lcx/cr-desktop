//! Chunk-based upload logic with streaming support and progress tracking

use crate::inventory::InventoryDb;
use crate::uploader::UploaderConfig;
use crate::uploader::encrypt::EncryptionConfig;
use crate::uploader::error::UploadError;
use crate::uploader::progress::{ProgressCallback, ProgressTracker};
use crate::uploader::providers::{self, PolicyType};
use crate::uploader::session::UploadSession;
use anyhow::{Context, Result};
use bytes::Bytes;
use cloudreve_api::Client as CrClient;
use futures::Stream;
use reqwest::Client as HttpClient;
use serde::{Deserialize, Serialize};
use std::io;
use std::path::Path;
use std::pin::Pin;
use std::sync::Arc;
use std::task::{Context as TaskContext, Poll};
use std::time::Duration;
use tokio::fs::File;
use tokio::io::{AsyncRead, AsyncSeekExt, BufReader, ReadBuf, SeekFrom};
use tokio_util::io::ReaderStream;
use tokio_util::sync::CancellationToken;
use tracing::{debug, error, info, warn};

/// Per-chunk progress tracking
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChunkProgress {
    /// Chunk index
    pub index: usize,
    /// Bytes uploaded for this chunk
    pub loaded: u64,
    /// ETag returned by storage provider (for S3-like providers)
    pub etag: Option<String>,
}

impl ChunkProgress {
    /// Create a new chunk progress entry
    pub fn new(index: usize) -> Self {
        Self {
            index,
            loaded: 0,
            etag: None,
        }
    }

    /// Check if chunk upload is complete
    pub fn is_complete(&self) -> bool {
        self.loaded > 0
    }
}

/// Metadata about a single chunk (without the data)
#[derive(Debug, Clone)]
pub struct ChunkInfo {
    /// Chunk index
    pub index: usize,
    /// Expected chunk size
    pub size: u64,
    /// Byte offset in file
    pub offset: u64,
}

impl ChunkInfo {
    /// Create new chunk info
    pub fn new(index: usize, offset: u64, size: u64) -> Self {
        Self {
            index,
            offset,
            size,
        }
    }
}

/// Buffer size for streaming reads (64KB)
const STREAM_BUFFER_SIZE: usize = 64 * 1024;

/// A limited async reader that reads only a specific range from a file,
/// optionally applying encryption on-the-fly.
pub struct ChunkReader {
    reader: BufReader<File>,
    // handle: ArcWin32Handle,
    // placeholder: Placeholder,
    encryption: Option<EncryptionConfig>,
    start_offset: u64,
    position: u64,
    remaining: u64,
}

impl ChunkReader {
    /// Create a new chunk reader for a specific byte range
    pub async fn new(
        path: &Path,
        offset: u64,
        size: u64,
        encryption: Option<EncryptionConfig>,
    ) -> Result<Self> {
        // let placeholder = OpenOptions::new()
        // .exclusive()
        //     .open(path)
        //     .context("failed to open file")?;
        // let protected_handle = placeholder
        //     .win32_handle()
        //     .context("failed to get win32 handle")?;
        let file = File::open(path).await.context("failed to open file")?;
        let mut reader = BufReader::with_capacity(STREAM_BUFFER_SIZE, file);
        reader.seek(SeekFrom::Start(offset)).await?;

        Ok(Self {
            reader,
            encryption,
            start_offset: offset,
            position: 0,
            remaining: size,
        })
    }

    /// Get the total size of this chunk
    #[allow(dead_code)]
    pub fn size(&self) -> u64 {
        self.position + self.remaining
    }
}

impl AsyncRead for ChunkReader {
    fn poll_read(
        mut self: Pin<&mut Self>,
        cx: &mut TaskContext<'_>,
        buf: &mut ReadBuf<'_>,
    ) -> Poll<io::Result<()>> {
        if self.remaining == 0 {
            return Poll::Ready(Ok(()));
        }

        // Limit read to remaining bytes
        let max_read = (self.remaining as usize).min(buf.remaining());
        let mut limited_buf = buf.take(max_read);
        let before = limited_buf.filled().len();

        // Pin the inner reader - this is safe because BufReader<File> is Unpin
        let reader = Pin::new(&mut self.reader);

        match reader.poll_read(cx, &mut limited_buf) {
            Poll::Ready(Ok(())) => {
                tracing::trace!(
                    target: "uploader::chunk",
                    bytes_read = limited_buf.filled().len() - before,
                    "Bytes read"
                );
                let bytes_read = limited_buf.filled().len() - before;
                if bytes_read == 0 {
                    // EOF reached
                    return Poll::Ready(Ok(()));
                }

                // Apply encryption if configured
                if let Some(ref config) = self.encryption {
                    let file_offset = self.start_offset + self.position;
                    // Get the newly read bytes and encrypt them in place
                    let start = buf.filled().len();
                    unsafe {
                        buf.assume_init(bytes_read);
                    }
                    buf.advance(bytes_read);
                    let filled = buf.filled_mut();
                    let encrypted_slice = &mut filled[start..start + bytes_read];
                    config.encrypt_at_offset(encrypted_slice, file_offset);
                } else {
                    unsafe {
                        buf.assume_init(bytes_read);
                    }
                    buf.advance(bytes_read);
                }

                self.position += bytes_read as u64;
                self.remaining -= bytes_read as u64;

                Poll::Ready(Ok(()))
            }
            Poll::Ready(Err(e)) => {
                tracing::error!(
                    target: "uploader::chunk",
                    error = ?e,
                    "Error reading chunk"
                );
                Poll::Ready(Err(e))
            }
            Poll::Pending => {
                tracing::trace!(
                    target: "uploader::chunk",
                    "Chunk reader is pending"
                );
                Poll::Pending
            }
        }
    }
}

/// A stream that yields chunks of bytes from a ChunkReader.
/// Uses tokio_util's ReaderStream internally for simplicity.
pub struct ChunkStream {
    inner: ReaderStream<ChunkReader>,
}

impl ChunkStream {
    /// Create a new chunk stream from a reader
    pub fn new(reader: ChunkReader) -> Self {
        Self {
            inner: ReaderStream::with_capacity(reader, STREAM_BUFFER_SIZE),
        }
    }

    /// Create a chunk stream from file path and chunk info
    pub async fn from_chunk(
        path: &Path,
        chunk: &ChunkInfo,
        encryption: Option<EncryptionConfig>,
    ) -> Result<Self> {
        let reader = ChunkReader::new(path, chunk.offset, chunk.size, encryption).await?;
        Ok(Self::new(reader))
    }
}

impl Stream for ChunkStream {
    type Item = Result<Bytes, io::Error>;

    fn poll_next(mut self: Pin<&mut Self>, cx: &mut TaskContext<'_>) -> Poll<Option<Self::Item>> {
        Pin::new(&mut self.inner).poll_next(cx)
    }
}

/// A stream wrapper that tracks progress at byte level.
/// Reports progress through the ProgressTracker with throttling.
pub struct ProgressStream<S> {
    inner: S,
    tracker: Arc<ProgressTracker>,
    bytes_sent_this_chunk: u64,
}

impl<S> ProgressStream<S> {
    /// Create a new progress-aware stream
    pub fn new(inner: S, tracker: Arc<ProgressTracker>) -> Self {
        Self {
            inner,
            tracker,
            bytes_sent_this_chunk: 0,
        }
    }

    /// Get bytes sent in this chunk stream
    #[allow(dead_code)]
    pub fn bytes_sent(&self) -> u64 {
        self.bytes_sent_this_chunk
    }
}

impl<S> Stream for ProgressStream<S>
where
    S: Stream<Item = Result<Bytes, io::Error>> + Unpin,
{
    type Item = Result<Bytes, io::Error>;

    fn poll_next(mut self: Pin<&mut Self>, cx: &mut TaskContext<'_>) -> Poll<Option<Self::Item>> {
        match Pin::new(&mut self.inner).poll_next(cx) {
            Poll::Ready(Some(Ok(bytes))) => {
                let len = bytes.len() as u64;
                self.bytes_sent_this_chunk += len;
                self.tracker.add_bytes(len);
                Poll::Ready(Some(Ok(bytes)))
            }
            other => other,
        }
    }
}

/// Chunk uploader that handles uploading chunks to different providers
pub struct ChunkUploader {
    http_client: HttpClient,
    cr_client: Arc<CrClient>,
    policy_type: PolicyType,
    config: UploaderConfig,
}

impl ChunkUploader {
    /// Create a new chunk uploader
    pub fn new(
        http_client: HttpClient,
        cr_client: Arc<CrClient>,
        policy_type: PolicyType,
        config: UploaderConfig,
    ) -> Self {
        Self {
            http_client,
            cr_client,
            policy_type,
            config,
        }
    }

    /// Upload all chunks for a file with progress tracking
    ///
    /// The progress_callback is wrapped in Arc so it can be shared with the
    /// background progress reporter task.
    pub async fn upload_all<P: ProgressCallback + 'static>(
        &self,
        local_path: &Path,
        session: &mut UploadSession,
        inventory: &InventoryDb,
        progress_callback: Arc<P>,
        cancel_token: &CancellationToken,
    ) -> Result<()> {
        info!(
            target: "uploader::chunk",
            local_path = %local_path.display(),
            num_chunks = session.num_chunks(),
            policy_type = ?self.policy_type,
            "Starting chunk upload"
        );

        // Get encryption config if needed
        let encryption = session
            .encrypt_metadata
            .as_ref()
            .map(|meta| EncryptionConfig::from_metadata(meta))
            .transpose()?;

        // Get pending chunks
        let pending_chunks = session.pending_chunks();
        if pending_chunks.is_empty() {
            info!(
                target: "uploader::chunk",
                "All chunks already uploaded"
            );
            return Ok(());
        }

        info!(
            target: "uploader::chunk",
            pending = pending_chunks.len(),
            total = session.num_chunks(),
            "Uploading pending chunks"
        );

        // Create progress tracker
        let tracker = ProgressTracker::new(session.file_size, session.num_chunks());

        // Initialize tracker with already completed chunks
        let completed_bytes: u64 = session
            .chunk_progress
            .iter()
            .filter(|c| c.is_complete())
            .map(|c| c.loaded)
            .sum();
        if completed_bytes > 0 {
            // Add completed bytes directly to completed_bytes counter
            for chunk in session.chunk_progress.iter().filter(|c| c.is_complete()) {
                tracker.complete_chunk(chunk.loaded);
            }
        }

        // Spawn progress reporter task
        let reporter_tracker = Arc::clone(&tracker);
        let reporter_cancel = cancel_token.clone();
        let reporter_callback = Arc::clone(&progress_callback);

        let reporter_handle = tokio::spawn(async move {
            loop {
                tokio::select! {
                    _ = tokio::time::sleep(Duration::from_millis(500)) => {
                        let update = reporter_tracker.create_update().await;
                        reporter_callback.on_progress(update);
                    }
                    _ = reporter_cancel.cancelled() => {
                        break;
                    }
                }
            }
        });

        // Upload chunks sequentially
        // TODO: Implement concurrent chunk upload with proper ordering
        let result = self
            .upload_chunks_sequential(
                local_path,
                session,
                inventory,
                &pending_chunks,
                encryption,
                &tracker,
                cancel_token,
            )
            .await;

        // Stop the reporter
        reporter_handle.abort();

        // Send final progress update
        let final_update = tracker.create_update().await;
        progress_callback.on_progress(final_update);

        result
    }

    /// Upload chunks sequentially
    async fn upload_chunks_sequential(
        &self,
        local_path: &Path,
        session: &mut UploadSession,
        inventory: &InventoryDb,
        pending_chunks: &[usize],
        encryption: Option<EncryptionConfig>,
        tracker: &Arc<ProgressTracker>,
        cancel_token: &CancellationToken,
    ) -> Result<()> {
        for &chunk_index in pending_chunks {
            // Check for cancellation
            if cancel_token.is_cancelled() {
                return Err(anyhow::anyhow!("Upload cancelled"));
            }

            // Get chunk info
            let (offset, _end) = session.chunk_range(chunk_index);
            let chunk_size = session.chunk_size_for(chunk_index);

            let chunk = ChunkInfo::new(chunk_index, offset, chunk_size);

            // Mark chunk as active
            tracker.start_chunk();

            // Upload with retries (stream is created inside retry loop)
            let etag = self
                .upload_chunk_with_retry(
                    local_path,
                    &chunk,
                    session,
                    encryption.clone(),
                    tracker,
                    cancel_token,
                )
                .await?;

            // Mark chunk as complete in tracker
            tracker.complete_chunk(chunk_size);

            // Update session progress
            session.complete_chunk(chunk_index, etag);

            // Persist progress to database (for resumability)
            if let Err(e) =
                inventory.update_upload_session_progress(&session.id, &session.chunk_progress)
            {
                warn!(
                    target: "uploader::chunk",
                    error = %e,
                    "Failed to persist chunk progress"
                );
            }
        }

        Ok(())
    }

    /// Upload a single chunk with retry logic
    async fn upload_chunk_with_retry(
        &self,
        local_path: &Path,
        chunk: &ChunkInfo,
        session: &UploadSession,
        encryption: Option<EncryptionConfig>,
        tracker: &Arc<ProgressTracker>,
        cancel_token: &CancellationToken,
    ) -> Result<Option<String>> {
        let mut bytes_sent_this_attempt: u64 = 0;

        for attempt in 0..=self.config.max_retries {
            if cancel_token.is_cancelled() {
                return Err(anyhow::anyhow!("Upload cancelled"));
            }

            if attempt > 0 {
                // Reset bytes from failed attempt
                if bytes_sent_this_attempt > 0 {
                    tracker.reset_chunk_bytes(bytes_sent_this_attempt);
                    bytes_sent_this_attempt = 0;
                }

                let delay = self.calculate_retry_delay(attempt);
                debug!(
                    target: "uploader::chunk",
                    chunk = chunk.index,
                    attempt,
                    delay_ms = delay.as_millis(),
                    "Retrying chunk upload"
                );

                tokio::select! {
                    _ = tokio::time::sleep(delay) => {}
                    _ = cancel_token.cancelled() => {
                        return Err(anyhow::anyhow!("Upload cancelled"));
                    }
                }
            }

            // Create a fresh stream for each attempt
            let inner_stream = ChunkStream::from_chunk(local_path, chunk, encryption.clone())
                .await
                .map_err(|e| {
                    UploadError::FileReadError(format!("Failed to create stream: {}", e))
                })?;

            // Wrap with progress tracking
            let progress_stream = ProgressStream::new(inner_stream, Arc::clone(tracker));

            match self.upload_chunk(chunk, progress_stream, session).await {
                Ok(etag) => {
                    debug!(
                        target: "uploader::chunk",
                        chunk = chunk.index,
                        etag = ?etag,
                        "Chunk uploaded successfully"
                    );
                    return Ok(etag);
                }
                Err(e) => {
                    if attempt == self.config.max_retries {
                        error!(
                            target: "uploader::chunk",
                            chunk = chunk.index,
                            error = ?e,
                            attempt,
                            "Chunk upload failed"
                        );
                        return Err(e);
                    }
                    warn!(
                        target: "uploader::chunk",
                        chunk = chunk.index,
                        error = ?e,
                        attempt,
                        "Chunk upload failed, will retry"
                    );
                }
            }
        }

        Err(anyhow::anyhow!("Chunk upload failed, max retries exceeded"))
    }

    /// Upload a single chunk (provider-specific)
    async fn upload_chunk<S>(
        &self,
        chunk: &ChunkInfo,
        stream: ProgressStream<S>,
        session: &UploadSession,
    ) -> Result<Option<String>>
    where
        S: Stream<Item = Result<Bytes, io::Error>> + Send + Sync + Unpin + 'static,
    {
        providers::upload_chunk_with_progress(
            &self.http_client,
            &self.cr_client,
            self.policy_type,
            chunk,
            stream,
            session,
        )
        .await
    }

    /// Calculate retry delay with exponential backoff
    fn calculate_retry_delay(&self, attempt: u32) -> Duration {
        let base = self.config.retry_base_delay.as_millis() as u64;
        let delay_ms = base * (1 << attempt.min(10)); // Cap exponential growth
        let delay = Duration::from_millis(delay_ms);
        delay.min(self.config.retry_max_delay)
    }
}
